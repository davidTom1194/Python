{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de883c6",
   "metadata": {},
   "source": [
    "##### D. Tom 11/2023\n",
    "# <center> SynoSearcher: Article and Web Link Finder</center>\n",
    "<b>Task: </b>*This Python 3 program first collects a set of user-defined words, then uses the Natural Language Toolkit (NLTK) to find their synonyms. Subsequently, it searches for and outputs relevant articles and web links associated with these keywords and their synonyms, providing a comprehensive resource compilation related to the input terms*."
    "<b>Note: </b>*Please read the section "Complexity" before attempting to run the program.  It can be time-consuming to run.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23975354",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Using a proof of concept, this project boradens the scope of data analysis and web scraping capabilities for additional free, open-source initiatives.  By integrating the Natural Language Toolkit (NLTK) with the Google-Search library, we harness Google's API to efficiently find and display synonyms, enhancing our data processing capabilities.\n",
    "\n",
    "The application of proper Data Science methods and techniques in this project allows for efficient resource allocation, facilitating the achievement of objectives in a cost-effective and timely manner.  This approach not only streamlines processes but also yields significant economic benefits, such as reduced operational costs and improved data-driven decision-making.\n",
    "\n",
    "<b>Note: Always verify the use case and comply with any applicable terms of service before using this project.</b>\n",
    "\n",
    "- <b>Understand Service Limitations:</b> Be aware of the limitations and restrictions of the services utlized, as these can influence the project's functionality and legal compliance.\n",
    "\n",
    "- <b>Data Privacy and Ethics:</b> Ensure adherence to privacy laws and ethical standards in data scraping and analysis, particularly when handling sensitive or proprietary information.\n",
    "\n",
    "- <b>Regular Updates and Maintenance:</b> Maintain the software with regular updates to integrate the latest NLTK and Google API advancements and to address any security vulnerabilities.\n",
    "\n",
    "- <b>Scalability and Performance:</b>Assess the scalability of the project, especially for large-scale data analysis, ensuring that the infrastructure is capable of handling increased data loads and processing demands.\n",
    "\n",
    "- <b>Emphasize Accuracy and Reliability:</b> Focus on the accuracy and reliability of data obtained through scraping, as this is critical for meaningful and valid analysis.\n",
    "\n",
    "- <b>Promote Collaboration and Knowledge Sharing:</b> Highlight the project's potential for collaboration within open-source communities, fostering innovation and collective learning.\n",
    "    \n",
    "- <b>User-Friendly Design:</b> If applicable, mention efforts to make the program accessible and easy to use, even for individuals with limited technical background in data science and web scraping.\n",
    "    \n",
    "This comprehensive approach ensures that the project not only meets its immediate objectives but also adheres to best practices in data science, fostering ethical, legal, and effective data utlization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1aa0cb",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "1. [Setting up the Environment](#0)<br>\n",
    "2. [Define Functions](#2)<br>\n",
    "2. [Input Phase](#4)<br>\n",
    "3. [Processing Phase](#6)<br>\n",
    "4. [Output Phase](#8)<br>\n",
    "5. [Main()](#10)<br>\n",
    "6. [Complexity](#12)<br>\n",
    "7. [Conclusion](#14)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e600ea",
   "metadata": {},
   "source": [
    "# Setting up the Environment<a id=\"0\"></a>\n",
    "The following setup enables the download and import of the NLTK and Google-Search libraries for the project's specific use cases. This environment includes modules that allow obtaining user input, generating a list of words associated with that input, and initiating web scraping. Additional optimization methods can be implemented to add, remove, or omit certain words and modules, tailoring them to the project's specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae5e04",
   "metadata": {},
   "source": [
    "##### Upgrade, Install, and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace57783",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!pip install --upgrade pyspellchecker\n",
    "!pip install --upgrade googlesearch-python nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17540a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package verbnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package verbnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('verbnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca392c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re     # for regular expressions on input\n",
    "import csv    # for csv file inputs\n",
    "from spellchecker import SpellChecker    # spelling check\n",
    "\n",
    "import itertools                   # iterate over permutations\n",
    "from nltk.corpus import wordnet    # Word corpus\n",
    "from nltk.corpus import verbnet    # Verb corpus\n",
    "from googlesearch import search    # Google search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0790e99",
   "metadata": {},
   "source": [
    "# Define Functions<a id=\"2\"></a>\n",
    "1. <b>Function Prototypes</b>\n",
    "\n",
    "    - <b>Input Phase</b>\n",
    "        - In this phase, input is obtained and stored for subsequent analysis.  This includes gathering data from various sources and preparing it for processing.\n",
    "            - load_words_from_file(file_name)\n",
    "            - process_user_input()\n",
    "            - check_spelling(words)\n",
    "            - split_string(input_string)\n",
    "            - get_input_from_user()\n",
    "    - <b>Processing Phase</b>\n",
    "        - During the processing phase, functions begin processing the input.  This involves performing calculations, data manipulation, and any necessary data transformations to prepare for output.\n",
    "            - perform_search(query_list)\n",
    "            - get_verbnet_classes(verb)\n",
    "            - search_wordnet(word)\n",
    "            - get_all_combinations(words_list, synonyms_dict)\n",
    "    - <b>Output Phase</b>\n",
    "        - The general output phase includes interactions with terminal/emulator I/O streams.  This involves displaying results, exporting data, or generating reports based on the processed input.\n",
    "            - print_search_results(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf4ca60",
   "metadata": {},
   "source": [
    "## Input Phase<a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a392dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file for input\n",
    "def load_words_from_file(file_name):\n",
    "    words = []\n",
    "    with open(file_name, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            words.extend(row)\n",
    "    return ' '.join(words)     # join words into a single string for split_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f86137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain words from user\n",
    "def get_input_from_user():\n",
    "    return input(\"Enter your word: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a350fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate words for analysis and processing\n",
    "def split_string(input_string):\n",
    "    # Splitting the string by spaces and punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b', input_string)\n",
    "    \n",
    "    # Storing words in a dictionary\n",
    "    word_dict = {f'word_{i}' : word for i, word in enumerate(words, start=1)}\n",
    "    \n",
    "    return words, word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0beb7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Check the spelling\n",
    "def check_spelling(words):\n",
    "    misspelled = spell.unknown(words)\n",
    "    corrected_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in misspelled:\n",
    "            # Get the most likely correction\n",
    "            corrected_word = spell.correction(word)\n",
    "            corrected_words.append(corrected_word)\n",
    "            print(f\"Correcting '{word}' to '{corrected_word}' \")\n",
    "        else:\n",
    "            corrected_words.append(word)\n",
    "            \n",
    "    return corrected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78bba7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process user input and prepare input for processing phase\n",
    "def process_user_input():\n",
    "    while True:\n",
    "        user_response = input(\"Do you have a file of words? (yes or no (y/n)): \").strip().lower()\n",
    "        if user_response == 'n':\n",
    "            user_words = get_input_from_user()\n",
    "            break\n",
    "        elif user_response == 'y':\n",
    "            file_name = input(\"Enter the file name: \")\n",
    "            user_words = load_words_from_file(file_name)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid response. Please enter 'y' or 'n'.\")\n",
    "\n",
    "    # words_list, words_dict = split_string(user_words)\n",
    "\n",
    "    return split_string(user_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a0f97",
   "metadata": {},
   "source": [
    "## Processing Phase<a id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf09809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all combinations of words and synonyms\n",
    "def get_all_combinations(words_list, synonyms_dict):\n",
    "    all_combinations = []\n",
    "    for word in words_list:\n",
    "        # Combine original/corrected words with its synonyms\n",
    "        options = synonyms_dict.get(word, [word])\n",
    "        all_combinations.append(set(options))\n",
    "    return list(set(itertools.product(*all_combinations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a110b58",
   "metadata": {},
   "source": [
    "##### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ff4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun synonyms\n",
    "def search_wordnet(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f6c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verb synonyms\n",
    "def get_verbnet_classes(verb):\n",
    "    return verbnet.classids(verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1eddcd",
   "metadata": {},
   "source": [
    "##### Google Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ee13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate words and perform search\n",
    "def perform_search(query_list):\n",
    "    results = {}\n",
    "    for query in query_list:\n",
    "        # Assuming 'search' is a function you have defined to perform web searches\n",
    "        results[query] = [url for url in search(query, num_results=1)]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451e075",
   "metadata": {},
   "source": [
    "## Output Phase<a id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ee9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output search results and urls\n",
    "def print_search_results(search_results):\n",
    "    for query, urls in search_results.items():\n",
    "        # Print the results\n",
    "        print(f\"Search Query: {query}\")\n",
    "        for url in urls:\n",
    "            print(url)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b3f60",
   "metadata": {},
   "source": [
    "## Main()<a id=\"10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "394b1230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you have a file of words? (yes or no (y/n)): n\n",
      "Enter your word: helli\n",
      "Correcting 'helli' to 'hell' \n",
      "Search Query: sin\n",
      "https://en.wikipedia.org/wiki/Sin\n",
      "https://www.merriam-webster.com/dictionary/sin\n",
      "https://www.britannica.com/topic/sin-religion\n",
      "\n",
      "\n",
      "Search Query: netherworld\n",
      "https://fearworld.com/\n",
      "https://fearworld.com/\n",
      "\n",
      "\n",
      "Search Query: hell_on_earth\n",
      "https://en.wikipedia.org/wiki/Hell_on_Earth_(Mobb_Deep_album)\n",
      "\n",
      "\n",
      "Search Query: Hades\n",
      "https://en.wikipedia.org/wiki/Hades\n",
      "https://www.supergiantgames.com/games/hades/\n",
      "https://store.steampowered.com/app/1145360/Hades/\n",
      "\n",
      "\n",
      "Search Query: hellhole\n",
      "https://www.imdb.com/title/tt19724142/\n",
      "https://en.wikipedia.org/wiki/Hellhole_(2022_film)\n",
      "\n",
      "\n",
      "Search Query: infernal_region\n",
      "https://www.vocabulary.com/dictionary/infernal%20region\n",
      "https://www.thefreedictionary.com/infernal+region\n",
      "\n",
      "\n",
      "Search Query: Hell\n",
      "https://en.wikipedia.org/wiki/Hell_in_Christianity\n",
      "\n",
      "\n",
      "Search Query: inferno\n",
      "https://www.imdb.com/title/tt3062096/\n",
      "https://en.wikipedia.org/wiki/Inferno_(2016_film)\n",
      "\n",
      "\n",
      "Search Query: the_pits\n",
      "https://www.merriam-webster.com/dictionary/the%20pits\n",
      "https://www.meetatthepit.com/\n",
      "https://www.collinsdictionary.com/us/dictionary/english/the-pits\n",
      "\n",
      "\n",
      "Search Query: perdition\n",
      "https://www.merriam-webster.com/dictionary/perdition\n",
      "https://www.dictionary.com/browse/perdition\n",
      "https://www.vocabulary.com/dictionary/perdition\n",
      "\n",
      "\n",
      "Search Query: blaze\n",
      "https://www.blazepizza.com/\n",
      "https://www.blazepizza.com/\n",
      "\n",
      "\n",
      "Search Query: nether_region\n",
      "https://en.wikipedia.org/wiki/Nether_region\n",
      "https://www.merriam-webster.com/dictionary/nether%20parts%2Fregions\n",
      "\n",
      "\n",
      "Search Query: snake_pit\n",
      "https://www.instagram.com/snake___pit/?hl=en\n",
      "https://www.instagram.com/snakepit_est.2016/?hl=en\n",
      "\n",
      "\n",
      "Search Query: Scheol\n",
      "https://www.vocabulary.com/dictionary/Scheol\n",
      "https://www.thefreedictionary.com/Scheol\n",
      "\n",
      "\n",
      "Search Query: pit\n",
      "https://www.merriam-webster.com/dictionary/pit\n",
      "https://flypittsburgh.com/\n",
      "\n",
      "\n",
      "Search Query: underworld\n",
      "https://www.imdb.com/title/tt0320691/\n",
      "https://en.wikipedia.org/wiki/Underworld_(film_series)\n",
      "https://underworldlive.com/\n",
      "\n",
      "\n",
      "Search Query: Inferno\n",
      "https://www.imdb.com/title/tt3062096/\n",
      "https://en.wikipedia.org/wiki/Inferno_(2016_film)\n",
      "\n",
      "\n",
      "Search Query: hell\n",
      "https://en.wikipedia.org/wiki/Hell_in_Christianity\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "words_list, words_dict = process_user_input()\n",
    "corrected_words_list = check_spelling(words_list)\n",
    "\n",
    "all_words = set(words_list + corrected_words_list)\n",
    "\n",
    "# Mapping each word (original or corrected) to its synonyms\n",
    "synonyms_dict = {word: search_wordnet(word) for word in all_words}\n",
    "\n",
    "# Get all combinations\n",
    "# all_unique_combinations = get_all_combinations(words_list, synonyms_dict)\n",
    "all_unique_combinations = get_all_combinations(corrected_words_list, synonyms_dict)\n",
    "\n",
    "# Combine words into search queries\n",
    "unique_search_queries = [' '.join(combination) for combination in all_unique_combinations]\n",
    "\n",
    "# Perform searches for each combined query\n",
    "search_results = perform_search(unique_search_queries)\n",
    "print_search_results(search_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28bd97",
   "metadata": {},
   "source": [
    "## Complexity<a id=\"12\"></a>\n",
    "To calculate the complexity of the system based on the given variables, we can develop an equation that takes into account the number of input words, the number of corrected words, the number of synonyms for each word, and the number of searches made. The complexity primarily depends on how these factors interact to produce the final number of results or operations.\n",
    "\n",
    "Let's define the variables as follows:\n",
    "\n",
    "- n = number of input words\n",
    "- c = number of corrected words (assuming each input word can be corrected)\n",
    "- s = number of synonyms per word\n",
    "- m = number of searches made\n",
    "\n",
    "The complexity equation can be outlined as:\n",
    "\n",
    "- Complexity=(n×s+c)×m\n",
    "\n",
    "Here's the rationale behind the equation:\n",
    "\n",
    "Input Words and Synonyms: For each input word, we generate 's' synonyms. So, the total number of outcomes from this part is n×s.\n",
    "\n",
    "Corrected Words: We add the number of corrected words, 'c'. This assumes that each input word might have a corrected version, which is considered as an additional outcome.\n",
    "\n",
    "Searches Made: Each combination of words (original, synonyms, and corrected) can lead to a search, so we multiply the above result by the number of searches made, 'm'.\n",
    "\n",
    "This equation assumes that:\n",
    "\n",
    "Each word is independent and can have 's' synonyms.\n",
    "Each word can be corrected, leading to additional outcomes.\n",
    "Each combination results in a unique search.\n",
    "This model provides a basic understanding of the system's complexity. However, it's a simplified representation. In practice, the interaction between these variables can be more complex, especially if synonyms and corrections interrelate or if certain combinations of words lead to more or fewer searches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3d5a8",
   "metadata": {},
   "source": [
    "## Conclusion<a id=\"14\"></a>\n",
    "The program functions by generating synonyms for each input word and combining these to produce a set of results.  Its operational efficiency is directly tied to the input's complexity and the number of synonyms requested.  For instance, with a single-word input like \"hello\" having 10 synonyms, the result is straightforward: 10 synonyms plus the original word, yielding 11 outcomes.  However, the scaling becomes more significant with a two-word input such as \"hello world\".  Here, the program generates synonyms for each word, considering 10 synonyms for each, leading to a multiplication of possibilities.  The total results then become 10 synonyms for 'hello' times 10 for 'world', amounting to 100 combinations, plus 4 additional outcomes for the combination of original and synonymous words.\n",
    "\n",
    "This illustrates the logarithmic growth in the program's output based on the inputs.  It's crucial to be aware of this exponential increase in results with the addition of more words and synonyms.  Such scaling can lead to a rapid escalation in the number of outcomes, potentially impacting the program's performance and mangeability of the results.  Users should exercise caution when increasing the number of input words and synonyms to avoid overwhelming system resources and to maintin practical usability of the output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
